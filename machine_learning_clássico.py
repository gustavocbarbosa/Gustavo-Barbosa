# -*- coding: utf-8 -*-
"""Machine Learning Clássico

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D6un6yB7NpK-1J5zVqww7MZH6eB0E1CK

# Primeiras Manipulações
"""

# Commented out IPython magic to ensure Python compatibility.
#Biblioteca para Manipulação de Dados
import pandas as pd
from scipy import stats

#Bibliotecas para Visualização de Dados
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

#Bibliotecas para Modelagem de Dados
from sklearn.preprocessing import StandardScaler, power_transform
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, StackingClassifier, BaggingClassifier, GradientBoostingClassifier
from sklearn.metrics import confusion_matrix
from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB
from sklearn.svm import SVC
from sklearn import svm, datasets
from sklearn.model_selection import GridSearchCV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree

#Biblioteca para importar os dados
import gdown

from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler

# %matplotlib inline

def download(id):
  url = 'https://drive.google.com/uc?id=' + str(id)
  gdown.download(url, output = None, quiet = False)

download('15Twjk504kGY3zWpKv5-M-0WMW2udDCHd')

# ler o arquivo .csv
df = pd.read_csv("winequality.csv")
df.drop(columns=['Unnamed: 0'], inplace=True)

# fazer um backup do dataset original
df_old = df.copy()

df.head()

"""## Normalização dos dados"""

df_norm = df.copy()

columns = list(df.columns)
features = columns[:-2]
labels = columns[-2:]

max_array, min_array = np.max(df[features], axis=0), np.min(df[features], axis=0)
df_norm[features] = (df_norm[features] - min_array)/(max_array - min_array)

df_norm.head()

"""# Implementação do KNN"""

def knn(X_test, X_train, y_train, K=3):

    labels = []

    for row in range(X_test.shape[0]):

        dist = np.mean((X_train - X_test[row,:])**2, axis=1)
        idx = dist.argsort()[:K]
        ngbs = y_train[idx]
        labels.append(stats.mode(ngbs)[0][0])

    return labels

"""# Classificação Binária para prever se o vinho é tinto ou não

*   SVM - Gustavo
*   Decision Tree - Joao 
*   Random Forest - Pedro Caio
*   Naive Bayes -

## Separação do dataset em treino e teste
"""

X = df[features]
X_norm = df_norm[features]
y_multi, y_bin = df[labels[0]], df[labels[1]]

X_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.2, random_state=1)
X_norm_train, X_norm_test, y_train, y_test = train_test_split(X_norm, y_bin, test_size=0.2, random_state=1)

acc_bin = []
labels_bin = []

"""## Decision Tree

*   É um método que pode ser usado para classificação e regressão.
*   Tem como objetivo prever o valor de uma variável usando regras inferidas
*   Quanta mais profunda a árvore, mais complexas são as regras de classificação
*   Classificado como white box model

Vantagens:
*   Exige pouco preparo dos dados
*   Resolve problemas com vários outputs de previsão

Desvantagens:
*   Pode criar árvore muito complexa que não generaliza bem os dados
*   Muito sensível a mudança dos dados, árvores muito distintas podem ser geradas com alterações pequenas

OBS: problema normalmente resolvido em um ensemble
*   Deve-se tomar cuidado com classes desbalanceados, isso pode enviesar os resultados negativamente

### Dados não normalizados
"""

tree_model_binary = DecisionTreeClassifier().fit(X_train, y_train)
acc_train = tree_model_binary.score(X_train, y_train)
acc_val = tree_model_binary.score(X_test, y_test)

acc_bin.append(acc_val)
labels_bin.append('DT')

print(f'Acurácia de treino: {100*acc_train:.2f} %')
print(f'Acurácia de validação: {100*acc_val:.2f} %')

y_pred = tree_model_binary.predict(X_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure()
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

print('\nFeature importance: ')
for feature, importance in zip(features, tree_model_binary.feature_importances_):
  print(f'{feature}: {importance:.3f}')

plt.figure()
sns.barplot(tree_model_binary.feature_importances_, features)

plt.figure(figsize=(100,100))
tree.plot_tree(tree_model_binary,max_depth=4)

"""### Dados Normalizados"""

tree_model_binary.fit(X_norm_train, y_train)
acc_train = tree_model_binary.score(X_norm_train, y_train)
acc_val = tree_model_binary.score(X_norm_test, y_test)

acc_bin.append(acc_val)
labels_bin.append('DT Norm')

print(f'Acurácia de treino: {100*acc_train:.2f} %')
print(f'Acurácia de validação: {100*acc_val:.2f} %')

y_pred = tree_model_binary.predict(X_norm_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

print('\nFeature importance: ')
for feature, importance in zip(features, tree_model_binary.feature_importances_):
  print(f'{feature}: {importance:.3f}')

plt.figure()
sns.barplot(tree_model_binary.feature_importances_, features)

plt.figure(figsize=(100,100))
tree.plot_tree(tree_model_binary,max_depth=4)

"""## Random Forest

Método que usa várias Decision Trees com subsets e combina as saídas. 

Melhora a acurácia e controla o overfitting

A variância é reduzida, podendo haver um pequeno aumento do bias

A redução da variância proporciona um modelo melhor
"""

model_rf = RandomForestClassifier(random_state=1)

"""### Dados não normalizados"""

model_rf.fit(X_train, y_train)
acc_train = model_rf.score(X_train, y_train)
acc_val = model_rf.score(X_test, y_test)

acc_bin.append(acc_val)
labels_bin.append('RF')

print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))

y_pred = model_rf.predict(X_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure()
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

print('\nFeature importance: ')
for feature, importance in zip(features, model_rf.feature_importances_):
  print('{}: {:.3f}'.format(feature, importance))

plt.figure()
sns.barplot(model_rf.feature_importances_, features)

"""### Dados normalizados"""

model_rf.fit(X_norm_train, y_train)
acc_train = model_rf.score(X_norm_train, y_train)
acc_val = model_rf.score(X_norm_test, y_test)

acc_bin.append(acc_val)
labels_bin.append('RF Norm')

print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))

y_pred = model_rf.predict(X_norm_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure()
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

print('\nFeature importance: ')
for feature, importance in zip(features, model_rf.feature_importances_):
  print('{}: {:.3f}'.format(feature, importance))

plt.figure()
sns.barplot(model_rf.feature_importances_, features)

"""## KNN

### Dados não normalizados
"""

for K in np.arange(1,10,2):
  y_pred = knn(X_test.to_numpy(), X_train.to_numpy(), y_train.to_numpy(), K=K)
  acc = np.sum(y_pred==y_test)/len(y_pred)

  acc_bin.append(acc)
  labels_bin.append('KNN - K = {}'.format(K))

  print('K = {}'.format(K))
  print('Accuracy: {:.2f} %'.format(acc*100))
  
  cf_matrix = confusion_matrix(y_test, y_pred)
  plt.figure()
  sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""### Dados normalizados"""

for K in np.arange(1,10,2):
  y_pred = knn(X_norm_test.to_numpy(), X_norm_train.to_numpy(), y_train.to_numpy(), K=K)
  acc = np.sum(y_pred==y_test)/len(y_pred)

  acc_bin.append(acc)
  labels_bin.append('KNN Norm - K = {}'.format(K))

  print('K = {}'.format(K))
  print('Accuracy: {:.2f} %'.format(acc*100))

  cf_matrix = confusion_matrix(y_test, y_pred)
  plt.figure()
  sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""## Naive Bayes

Esses modelos baseiam-se no teorema de Bayes

É dito "naive" pois tem como presuposto a independência das variáveis

Mesmo parecendo simplificado, já funcionou bem com problemas práticos

Possui algumas variações, cada uma supõe que os dados estão distribuídos de determinada maneira

É um classificador bom, mas um estimador ruim, como assume independência das variáveis, as porcentagens de correlação em si não muito corretas. Ou seja, acaba acertando a categoria, mas o grau de certeza não representa a realidade

### Dados não normalizados
"""

model_nb = [GaussianNB(), MultinomialNB(), ComplementNB(), BernoulliNB()]
name_model = ['Gaussian Naive Bayes', 'Multinomial Naive Bayes', 'Complement Naive Bayes', 'Bernoulli Naive Bayes']

for model, name in zip(model_nb, name_model):
  model.fit(X_train, y_train)

  acc_train = model.score(X_train, y_train)
  acc_val = model.score(X_test, y_test)

  acc_bin.append(acc_val)
  labels_bin.append(name)

  print(name)
  print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
  print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
  print()

  y_pred = model.predict(X_test)
  cf_matrix = confusion_matrix(y_test, y_pred)
  plt.figure()
  sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""### Dados normalizados"""

for model, name in zip(model_nb, name_model):
  model.fit(X_norm_train, y_train)

  acc_train = model.score(X_norm_train, y_train)
  acc_val = model.score(X_norm_test, y_test)

  acc_bin.append(acc_val)
  labels_bin.append('{} Norm'.format(name))

  print(name)
  print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
  print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
  print()

  y_pred = model.predict(X_norm_test)
  cf_matrix = confusion_matrix(y_test, y_pred)
  plt.figure()
  sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""## SVM

Método usado para problemas de classificação, regressão e detecção de outliers

Funciona por meio de hiperplanos, ou conjunto de hiperplanos para separar os dados  

Vantagens:

*   Efetivo em espaços com muitas dimensões
*   Funciona bem mesmo quando o número de dimensões é maior que o conjunto de dados
*   Usa um subset do conjunto de treinamento na função de decisão, então é eficiente no quesito memória
*   Versátil, pois admite variação da função de kernel  

 

OBS:


*   Se o número de features for muito maior do que o de exemplos, deve-se fazer uma escolha adequada de kernel function
*   SVM não disponibilizam diretamente as estimativas de probabilidade. Essas sãao calculadas por meio de um custoso 5-fold cross validation
"""

svclassifier = SVC(kernel='linear')

"""### Dados não normalizados"""

svclassifier.fit(X_train, y_train)
acc_trainsvm = svclassifier.score(X_train, y_train)
acc_valsvm = svclassifier.score(X_test, y_test)

acc_bin.append(acc_valsvm)
labels_bin.append('SVM')

print('Acurácia de treino: {:.2f} %'.format(100*acc_trainsvm))
print('Acurácia de validação: {:.2f} %'.format(100*acc_valsvm))

y_pred = svclassifier.predict(X_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure()
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""### Dados Normalizados"""

svclassifier.fit(X_norm_train, y_train)
acc_trainsvm = svclassifier.score(X_norm_train, y_train)
acc_valsvm = svclassifier.score(X_norm_test, y_test)

acc_bin.append(acc_valsvm)
labels_bin.append('SVM Norm')

print('Acurácia de treino: {:.2f} %'.format(100*acc_trainsvm))
print('Acurácia de validação: {:.2f} %'.format(100*acc_valsvm))

y_pred = svclassifier.predict(X_norm_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure()
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""## Stacking"""

estimators = [('rf', model_rf),
              ('svr', svclassifier),
              ('knn', KNeighborsClassifier(n_neighbors=3)),
              ('nb', model_nb[0]),
              ('lr', LogisticRegression())]
               
model_stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())

"""### Dados normalizados"""

model_stacking.fit(X_norm_train, y_train)
acc_train = model_stacking.score(X_norm_train, y_train)
acc_val = model_stacking.score(X_norm_test, y_test)

acc_bin.append(acc_val)
labels_bin.append('Stacking Norm')

print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))

y_pred = model_stacking.predict(X_norm_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure()
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""## Boosting

### Dados normalizados
"""

lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1] # lista de learning rates pra gente analisar qual é mais efetivo

for learning_rate in lr_list:
    model_boosting = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)
    model_boosting.fit(X_norm_train, y_train)
    acc_train = model_boosting.score(X_norm_train, y_train)
    acc_val = model_boosting.score(X_norm_test, y_test)

    acc_bin.append(acc_val)
    labels_bin.append('Boosting Norm (Learning Rate = {0:.3f})'.format(learning_rate))

    print("Learning rate: ", learning_rate)
    print("Accuracy score (training): {0:.3f} %".format(100*acc_train))
    print("Accuracy score (validation): {0:.3f} %".format(100*acc_val))
    y_pred = model_boosting.predict(X_norm_test)
    cf_matrix = confusion_matrix(y_test, y_pred)
    plt.figure()
    sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""## Comparação Geral

"""

plt.figure(figsize=(7,7))
sns.barplot(acc_bin, labels_bin)

max_idx = np.where(np.array(acc_bin) == np.max(acc_bin))[0]

print('Maior(es) acurácia(s) - {:.2f} %:'.format(100*np.max(acc_bin)))
for idx in max_idx:
  print('\t{}'.format(labels_bin[idx]))

"""# Classificação multiclasse para prever a qualidade do vinho

*   SVM - Gustavo
*   Decision Tree - Joao 
*   Random Forest - Pedro Caio
*   Naive Bayes -

## Separação do dataset em treino e teste
"""

X_train, X_test, y_train, y_test = train_test_split(X, y_multi, test_size=0.2, random_state=1)
X_norm_train, X_norm_test, y_train, y_test = train_test_split(X_norm, y_multi, test_size=0.2, random_state=1)

acc_multi = []
labels_multi = []

"""Fazendo o oversampling para o problema multiclasse com os dados normalizados

"""

oversample = RandomOverSampler(sampling_strategy='minority')

X_over, y_over = X_norm_train, y_train

for i in range(len(df_norm['quality'].unique())):
    X_over, y_over = oversample.fit_resample(X_over, y_over)
    
label_count = []
for label in df_norm['quality'].unique():
    label_count.append(np.sum(y_over==label))

print(label_count)

"""Fazendo o undersampling para o problema multiclasse com os dados normalizados


"""

undersample = RandomUnderSampler(sampling_strategy='majority')

X_under, y_under = X_norm_train, y_train

for i in range(len(df_norm['quality'].unique())):
    X_under, y_under = undersample.fit_resample(X_under, y_under)
    
label_count = []
for label in df_norm['quality'].unique():
    label_count.append(np.sum(y_under==label))

print(label_count)

"""## Decision Tree

###Dados não normalizados
"""

tree_model_multi = DecisionTreeClassifier().fit(X_train, y_train)

acc_train = tree_model_multi.score(X_train, y_train)
acc_val = tree_model_multi.score(X_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('DT')

print(f'Acurácia de treino: {100*acc_train:.2f}')
print(f'Acurácia de validação: {100*acc_val:.2f}')

y_pred = tree_model_multi.predict(X_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

print('\nFeature importance: ')
for feature, importance in zip(features, tree_model_multi.feature_importances_):
  print(f'{feature}: {importance:.3f}')

plt.figure()
sns.barplot(tree_model_multi.feature_importances_, features)

plt.figure(figsize=(100,100))
tree.plot_tree(tree_model_multi,max_depth=4)

"""### Dados Normalizados"""

tree_model_multi.fit(X_norm_train, y_train)
acc_train = tree_model_multi.score(X_norm_train, y_train)
acc_val = tree_model_multi.score(X_norm_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('DT Norm')

print(f'Acurácia de treino: {100*acc_train:.2f} %')
print(f'Acurácia de validação: {100*acc_val:.2f} %')

y_pred = tree_model_multi.predict(X_norm_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

print('\nFeature importance: ')
for feature, importance in zip(features, tree_model_multi.feature_importances_):
  print(f'{feature}: {importance:.3f}')

plt.figure()
sns.barplot(tree_model_multi.feature_importances_, features)

plt.figure(figsize=(100,100))
tree.plot_tree(tree_model_multi,max_depth=4)

"""## Random Forest"""

model_rf = RandomForestClassifier(random_state=1)

max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
max_depth.append(None)
max_features = ['auto', 'sqrt', 'log2']

parameters = {'max_depth': max_depth, 'max_features': max_features}

clf = GridSearchCV(model_rf, parameters)

"""### Dados não normalizados"""

model_rf.fit(X_train, y_train)
acc_train = model_rf.score(X_train, y_train)
acc_val = model_rf.score(X_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('RF')

print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))

y_pred = model_rf.predict(X_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

print('\nFeature importance: ')
for feature, importance in zip(features, model_rf.feature_importances_):
  print('{}: {:.3f}'.format(feature, importance))

plt.figure()
sns.barplot(model_rf.feature_importances_, features)

"""### Dados normalizados"""

model_rf.fit(X_norm_train, y_train)
acc_train = model_rf.score(X_norm_train, y_train)
acc_val = model_rf.score(X_norm_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('RF Norm')

print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))

y_pred = model_rf.predict(X_norm_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

print('\nFeature importance: ')
for feature, importance in zip(features, model_rf.feature_importances_):
  print('{}: {:.3f}'.format(feature, importance))

plt.figure()
sns.barplot(model_rf.feature_importances_, features)

"""### Dados com oversample"""

model_rf.fit(X_over, y_over)
acc_train = model_rf.score(X_over, y_over)
acc_val = model_rf.score(X_norm_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('RF Over')

print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))

y_pred = model_rf.predict(X_norm_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

print('\nFeature importance: ')
for feature, importance in zip(features, model_rf.feature_importances_):
  print('{}: {:.3f}'.format(feature, importance))

plt.figure()
sns.barplot(model_rf.feature_importances_, features)

"""## KNN

### Dados não-normalizados
"""

for K in np.arange(1,10,2):
  y_pred = knn(X_test.to_numpy(), X_train.to_numpy(), y_train.to_numpy(), K=K)
  acc = np.sum(y_pred==y_test)/len(y_pred)

  acc_multi.append(acc)
  labels_multi.append('KNN - K = {}'.format(K))

  print('K = {}'.format(K))
  print('Accuracy: {:.2f} %'.format(acc*100))

  cf_matrix = confusion_matrix(y_test, y_pred)
  plt.figure(figsize=(10,10))
  sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""### Dados normalizados"""

for K in np.arange(1,10,2):
  y_pred = knn(X_norm_test.to_numpy(), X_norm_train.to_numpy(), y_train.to_numpy(), K=K)
  acc = np.sum(y_pred==y_test)/len(y_pred)

  acc_multi.append(acc)
  labels_multi.append('KNN Norm - K = {}'.format(K))

  print('K = {}'.format(K))
  print('Accuracy: {:.2f} %'.format(acc*100))

  cf_matrix = confusion_matrix(y_test, y_pred)
  plt.figure(figsize=(10,10))
  sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""### Dados com oversample"""

for K in np.arange(1,10,2):
  y_pred = knn(X_norm_test.to_numpy(), X_over, y_over, K=K)
  acc = np.sum(y_pred==y_test)/len(y_pred)

  acc_multi.append(acc)
  labels_multi.append('KNN Oversample - K = {}'.format(K))

  print('K = {}'.format(K))
  print('Accuracy: {:.2f} %'.format(acc*100))

  cf_matrix = confusion_matrix(y_test, y_pred)
  plt.figure(figsize=(10,10))
  sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""### Dados com undersample"""

for K in np.arange(1,10,2):
  y_pred = knn(X_norm_test.to_numpy(), X_under, y_under, K=K)
  acc = np.sum(y_pred==y_test)/len(y_pred)

  acc_multi.append(acc)
  labels_multi.append('KNN Undersample - K = {}'.format(K))

  print('K = {}'.format(K))
  print('Accuracy: {:.2f} %'.format(acc*100))

  cf_matrix = confusion_matrix(y_test, y_pred)
  plt.figure(figsize=(10,10))
  sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""## Naive Bayes

### Dados não normalizados
"""

model_nb = [GaussianNB(), MultinomialNB(), ComplementNB(), BernoulliNB()]
name_model = ['Gaussian Naive Bayes', 'Multinomial Naive Bayes', 'Complement Naive Bayes', 'Bernoulli Naive Bayes']

for model, name in zip(model_nb, name_model):
  model.fit(X_train, y_train)

  acc_train = model.score(X_train, y_train)
  acc_val = model.score(X_test, y_test)

  acc_multi.append(acc_val)
  labels_multi.append(name)

  print(name)
  print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
  print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
  print()

  y_pred = model.predict(X_test)
  cf_matrix = confusion_matrix(y_test, y_pred)
  plt.figure(figsize=(10,10))
  sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""### Dados normalizados"""

for model, name in zip(model_nb, name_model):
  model.fit(X_norm_train, y_train)

  acc_train = model.score(X_norm_train, y_train)
  acc_val = model.score(X_norm_test, y_test)

  acc_multi.append(acc_val)
  labels_multi.append('{} Norm'.format(name))

  print(name)
  print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
  print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
  print()

  y_pred = model.predict(X_norm_test)
  cf_matrix = confusion_matrix(y_test, y_pred)
  plt.figure(figsize=(10,10))
  sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""### Dados com oversample"""

for model, name in zip(model_nb, name_model):
  model.fit(X_over, y_over)

  acc_train = model.score(X_over, y_over)
  acc_val = model.score(X_norm_test, y_test)

  acc_multi.append(acc_val)
  labels_multi.append('{} Oversample'.format(name))

  print(name)
  print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
  print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
  print()

  y_pred = model.predict(X_norm_test)
  cf_matrix = confusion_matrix(y_test, y_pred)
  plt.figure(figsize=(10,10))
  sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""## Kernel SVM"""

parameters = {'degree': [2,3,4,5,6,7,8], 'kernel': ['poly']}
svc = svm.SVC()
clf = GridSearchCV(svc, parameters)

svclassifierpoly = SVC(kernel='poly', degree=8)
svclassifiergaussian = SVC(kernel='rbf')
svclassifiersigmoid = SVC(kernel='sigmoid')

"""### Dados Não normalizados"""

svclassifiergaussian.fit(X_train, y_train)
acc_train = svclassifiergaussian.score(X_train, y_train)
acc_val = svclassifiergaussian.score(X_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('SVM Gaussian')

print('GAUSSIAN KERNEL')
print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
print()

y_pred = svclassifiergaussian.predict(X_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

svclassifiersigmoid.fit(X_train, y_train)
acc_train = svclassifiersigmoid.score(X_train, y_train)
acc_val = svclassifiersigmoid.score(X_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('SVM Sigmoid')

print('SIGMOID KERNEL')
print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
print()

y_pred = svclassifiersigmoid.predict(X_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

svclassifierpoly.fit(X_train, y_train)
acc_train = svclassifierpoly.score(X_train, y_train)
acc_val = svclassifierpoly.score(X_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('SVM Polynomial')

print('POLYNOMIAL KERNEL')
print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
print()

y_pred = svclassifierpoly.predict(X_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""### Dados Normalizados"""

svclassifiergaussian.fit(X_norm_train, y_train)
acc_train = svclassifiergaussian.score(X_norm_train, y_train)
acc_val = svclassifiergaussian.score(X_norm_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('SVM Gaussian Norm')

print('GAUSSIAN KERNEL')
print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
print()

y_pred = svclassifiergaussian.predict(X_norm_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

svclassifiersigmoid.fit(X_norm_train, y_train)
acc_train = svclassifiersigmoid.score(X_norm_train, y_train)
acc_val = svclassifiersigmoid.score(X_norm_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('SVM Sigmoid Norm')

print('SIGMOID KERNEL')
print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
print()

y_pred = svclassifiersigmoid.predict(X_norm_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

# svclassifierpoly.fit(X_norm_train, y_train)
# acc_train = svclassifierpoly.score(X_norm_train, y_train)
# acc_val = svclassifierpoly.score(X_norm_test, y_test)

# acc_multi.append(acc_val)
# labels_multi.append('SVM Polynomial Norm')

# print('POLYNOMIAL KERNEL')
# print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
# print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
# print()

# y_pred = svclassifierpoly.predict(X_norm_test)
# cf_matrix = confusion_matrix(y_test, y_pred)
# plt.figure(figsize=(10,10))
# sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""### Dados com oversample"""

svclassifiergaussian.fit(X_over, y_over)
acc_train = svclassifiergaussian.score(X_over, y_over)
acc_val = svclassifiergaussian.score(X_norm_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('SVM Gaussian Oversample')

print('GAUSSIAN KERNEL')
print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
print()

y_pred = svclassifiergaussian.predict(X_norm_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

svclassifiersigmoid.fit(X_over, y_over)
acc_train = svclassifiersigmoid.score(X_over, y_over)
acc_val = svclassifiersigmoid.score(X_norm_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('SVM Sigmoid Oversample')

print('SIGMOID KERNEL')
print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
print()

y_pred = svclassifiersigmoid.predict(X_norm_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

# svclassifierpoly.fit(X_over, y_over)
# acc_train = svclassifierpoly.score(X_over, y_over)
# acc_val = svclassifierpoly.score(X_norm_test, y_test)

# acc_multi.append(acc_val)
# labels_multi.append('SVM Polynomial Oversample')

# print('POLYNOMIAL KERNEL')
# print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
# print('Acurácia de validação: {:.2f} %'.format(100*acc_val))
# print()

# y_pred = svclassifierpoly.predict(X_norm_test)
# cf_matrix = confusion_matrix(y_test, y_pred)
# plt.figure(figsize=(10,10))
# sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""## Stacking"""

estimators = [('rf', model_rf),
              ('svr', svclassifier),
              ('knn', KNeighborsClassifier(n_neighbors=3)),
              ('nb', model_nb[0]),
              ('lr', LogisticRegression())]
               
model_stacking = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())

"""### Dados normalizados"""

model_stacking.fit(X_norm_train, y_train)
acc_train = model_stacking.score(X_norm_train, y_train)
acc_val = model_stacking.score(X_norm_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('Stacking Norm')

print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))

y_pred = model_stacking.predict(X_norm_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""### Dados com oversample"""

model_stacking.fit(X_over, y_over)
acc_train = model_stacking.score(X_over, y_over)
acc_val = model_stacking.score(X_norm_test, y_test)

acc_multi.append(acc_val)
labels_multi.append('Stacking Oversample')

print('Acurácia de treino: {:.2f} %'.format(100*acc_train))
print('Acurácia de validação: {:.2f} %'.format(100*acc_val))

y_pred = model_stacking.predict(X_norm_test)
cf_matrix = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""## Boosting

### Dados normalizados
"""

lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1] # lista de learning rates pra gente analisar qual é mais efetivo

for learning_rate in lr_list:
    model_boosting = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)
    model_boosting.fit(X_norm_train, y_train)
    acc_train = model_boosting.score(X_norm_train, y_train)
    acc_val = model_boosting.score(X_norm_test, y_test)

    acc_bin.append(acc_val)
    labels_bin.append('Boosting Norm (Learning Rate = {0:.3f}'.format(learning_rate))

    print("Learning rate: ", learning_rate)
    print("Accuracy score (training): {0:.3f} %".format(100*acc_train))
    print("Accuracy score (validation): {0:.3f} %".format(100*acc_val))
    y_pred = model_boosting.predict(X_norm_test)
    cf_matrix = confusion_matrix(y_test, y_pred)
    plt.figure()
    sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""### Dados com oversample"""

lr_list = [0.05, 0.075, 0.1, 0.25, 0.5, 0.75, 1] # lista de learning rates pra gente analisar qual é mais efetivo

for learning_rate in lr_list:
    model_boosting = GradientBoostingClassifier(n_estimators=20, learning_rate=learning_rate, max_features=2, max_depth=2, random_state=0)
    model_boosting.fit(X_over, y_over)
    acc_train = model_boosting.score(X_over, y_over)
    acc_val = model_boosting.score(X_norm_test, y_test)

    acc_multi.append(acc_val)
    labels_multi.append('Boosting Norm (Learning Rate = {0:.3f}'.format(learning_rate))

    print("Learning rate: ", learning_rate)
    print("Accuracy score (training): {0:.3f} %".format(100*acc_train))
    print("Accuracy score (validation): {0:.3f} %".format(100*acc_val))
    y_pred = model_boosting.predict(X_norm_test)
    cf_matrix = confusion_matrix(y_test, y_pred)
    plt.figure()
    sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True)

"""## Comparação Geral"""

plt.figure(figsize=(9,9))
sns.barplot(acc_multi, labels_multi)

max_idx = np.where(np.array(acc_multi) == np.max(acc_multi))[0]

print('Maior(es) acurácia(s) - {:.2f} %:'.format(100*np.max(acc_multi)))
for idx in max_idx:
  print('\t{}'.format(labels_multi[idx]))